{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with spike-field coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# On-ramp: compute the spike-field cohernece\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to load in spike and field data, and compute the spike-field coherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as io\n",
    "import scipy.signal as signal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#%matplotlib tk\n",
    "\n",
    "# Load the data and plot it.\n",
    "data = io.loadmat('spikes-LFP-1.mat')       # Load the multiscale data,\n",
    "y = data['y']                                # ... get the LFP data,\n",
    "n = data['n']                                # ... get the spike data,\n",
    "t = data['t'].reshape(-1)                    # ... get the time axis,\n",
    "K = np.shape(n)[0]                           # Get the number of trials,\n",
    "N = np.shape(n)[1]                           # ... and the number of data points in each trial,\n",
    "dt = t[1]-t[0]                               # Get the sampling interval.\n",
    "\n",
    "SYY = np.zeros(int(N/2+1))                                       # Variable to store field spectrum.\n",
    "SNN = np.zeros(int(N/2+1))                                       # Variable to store spike spectrum.\n",
    "SYN = np.zeros(int(N/2+1), dtype=complex)                        # Variable to store cross spectrum.\n",
    "\n",
    "for k in np.arange(K):                                           # For each trial,\n",
    "    yf = np.fft.rfft((y[k,:]-np.mean(y[k,:])) *np.hanning(N))    # Hanning taper the field,\n",
    "    nf = np.fft.rfft((n[k,:]-np.mean(n[k,:])))                   # ... but do not taper the spikes.\n",
    "    SYY = SYY + ( np.real( yf*np.conj(yf) ) )/K                  # Field spectrum\n",
    "    SNN = SNN + ( np.real( nf*np.conj(nf) ) )/K                  # Spike spectrum\n",
    "    SYN = SYN + (          yf*np.conj(nf)   )/K                  # Cross spectrum\n",
    "\n",
    "cohr = np.abs(SYN) / np.sqrt(SYY) / np.sqrt(SNN)                 # Spike-field coherence\n",
    "f = np.fft.rfftfreq(N, dt)                                       # Frequency axis for plotting\n",
    "\n",
    "plt.plot(f,cohr)                             # Plot the result.\n",
    "plt.xlim([0, 100])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('Coherence');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Dependence on rate (Part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For convenience, make a function to compute the cohernece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coherence(n,y,t):                           #INPUT (spikes, fields, time)\n",
    "    K = np.shape(n)[0]                          #... where spikes and fields are arrays [trials, time]\n",
    "    N = np.shape(n)[1]\n",
    "    T = t[-1]\n",
    "    SYY = np.zeros(int(N/2+1))\n",
    "    SNN = np.zeros(int(N/2+1))\n",
    "    SYN = np.zeros(int(N/2+1), dtype=complex)\n",
    "    \n",
    "    for k in np.arange(K):\n",
    "        yf = np.fft.rfft((y[k,:]-np.mean(y[k,:])) *np.hanning(N))    # Hanning taper the field,\n",
    "        nf = np.fft.rfft((n[k,:]-np.mean(n[k,:])))                   # ... but do not taper the spikes.\n",
    "        SYY = SYY + ( np.real( yf*np.conj(yf) ) )/K                  # Field spectrum\n",
    "        SNN = SNN + ( np.real( nf*np.conj(nf) ) )/K                  # Spike spectrum\n",
    "        SYN = SYN + (          yf*np.conj(nf)   )/K                  # Cross spectrum\n",
    "\n",
    "    cohr = np.abs(SYN) / np.sqrt(SYY) / np.sqrt(SNN)                 # Coherence\n",
    "    f = np.fft.rfftfreq(N, dt)                                       # Frequency axis for plotting\n",
    "    \n",
    "    return (cohr, f, SYY, SNN, SYN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[cohr, f, SYY, SNN, SYN] = coherence(n,y,t)\n",
    "plt.plot(f,cohr)\n",
    "plt.xlim([0, 100]); plt.xlabel('Frequency [Hz]'); plt.ylabel('Coherence');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a function to thin a spike train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thinned_spike_train(n, thinning_factor):              # Thin the spike train (n) by the thinning_factor.\n",
    "    n_thinned = np.copy(n)                                # Make a copy of the spike train data.\n",
    "    for k in np.arange(K):                                # For each trial,\n",
    "        spike_times = np.where(n[k,:]==1)                 # ...find the spikes.\n",
    "        n_spikes = np.size(spike_times)                   # ...determine number of spikes.\n",
    "        spike_times_random = spike_times[0][np.random.permutation(n_spikes)]    # ...permute spikes indices,\n",
    "        n_remove=int(np.floor(thinning_factor*n_spikes))  # ... determine number of spikes to remove,\n",
    "        n_thinned[k,spike_times_random[1:n_remove]]=0     # remove the spikes.\n",
    "    return n_thinned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "plt.plot(t, n[0,:], 'k')\n",
    "plt.plot(t, thinned_spike_train(n,0.5)[0,:], 'r');\n",
    "plt.xlim([0.2, 0.3])\n",
    "plt.legend(['Original', 'Thinned']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the spike-field coherence for original and thinned data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[cohr, f, SYY, SNN, SYN] = coherence(n,y,t)                          # Coherence for original spike train.\n",
    "plt.clf()\n",
    "plt.plot(f,cohr, 'b')\n",
    "[cohr, f, SYY, SNN, SYN] = coherence(thinned_spike_train(n,0.9),y,t) # ... and for the thinned spike train.\n",
    "plt.plot(f,cohr, 'r')\n",
    "plt.xlim([40, 50])\n",
    "plt.legend(['Original', 'Thinned'])\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('Coherence');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: At what phases are the spikes removed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a function to compute field phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_field_phase(y):\n",
    "    phi = np.zeros([K,N])\n",
    "    for k in np.arange(K):                               # For each trial,\n",
    "        phi[k,:] = np.angle(signal.hilbert(y[k,:]))      #  ... compute phase of the field\n",
    "    return phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute field phase at each spike removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi                     = get_field_phase(y)\n",
    "spikes_removed          = n - thinned_spike_train(n,0.5)\n",
    "phase_at_spikes_removed = phi[spikes_removed == 1]\n",
    "plt.clf()\n",
    "plt.hist(phase_at_spikes_removed);\n",
    "plt.xlabel('Phase')\n",
    "plt.ylabel('Counts');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat for different thinning factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1); plt.clf(); plt.figure(2); plt.clf()\n",
    "counter=1\n",
    "for thinner in np.arange(0,1,0.25):\n",
    "    thinned = thinned_spike_train(n,thinner)\n",
    "    [cohr, f, SYY, SNN, SYN] = coherence(thinned,y,t) # ... and for the thinned spike train.\n",
    "    plt.figure(1)\n",
    "    plt.plot(f,cohr,label=str(thinner))\n",
    "    \n",
    "    phi                     = get_field_phase(y)\n",
    "    spikes_removed          = n - thinned\n",
    "    phase_at_spikes_removed = phi[spikes_removed == 1]\n",
    "    plt.figure(2)\n",
    "    plt.subplot(4,1,counter); counter=counter+1;\n",
    "    plt.hist(phase_at_spikes_removed); plt.title(str(thinner)); plt.xlabel('Phase'); plt.ylabel('Counts')\n",
    "\n",
    "plt.figure(1)\n",
    "plt.xlim([40, 50])\n",
    "plt.legend()\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('Coherence');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Dependence on rate (Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate two simple spiking neurons, with activity dependent on a field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_two_neurons(baseline_rate_A, baseline_rate_B, field_coupling_A, field_coupling_B):\n",
    "    K = 100                            # Number of trials.\n",
    "    N = 1000                           # Points per trial.\n",
    "    A = np.zeros([K,N])                # Array to hold spikes A.\n",
    "    B = np.zeros([K,N])                # Array to hold spikes B.\n",
    "    y = np.zeros([K,N])                # Array to hold field.\n",
    "    for k in np.arange(K):             # For each trial,\n",
    "        y[k,:] = np.sin(2*np.pi*t*10) + 0.1*np.random.randn(N)    # ... generate a field,\n",
    "        A[k,:] = np.random.binomial(1,0.001*np.exp(baseline_rate_A+field_coupling_A*y[k,:]))      # ... generate spikes #A that depend on the field,\n",
    "        B[k,:] = np.random.binomial(1,0.001*np.exp(baseline_rate_B+field_coupling_B*y[k,:]))      # ... generate spikes #B that depend on the field.\n",
    "    return A,B,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize example trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "rate_A = 1.0;  coupling_A = 0.5            # Fix the rates and coupling to field for each neuron.\n",
    "rate_B = 1.0;  coupling_B = 0.5             # Simulate the two neurons.\n",
    "A,B,y = sim_two_neurons(rate_A, rate_B, coupling_A, coupling_B)\n",
    "n_trial = 0;                                # Select a trial to plot.\n",
    "plt.plot(t,A[n_trial,:])\n",
    "plt.plot(t,B[n_trial,:])\n",
    "plt.plot(t,y[n_trial,:])\n",
    "plt.legend([\"Neuron A\", \"Neuron B\", \"Field\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the average rate of each neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rateA = np.mean(sum(A,1)/t[-1])\n",
    "rateB = np.mean(sum(B,1)/t[-1])\n",
    "\n",
    "print(\"A(Rate) = \", rateA, \", B(Rate) = \", rateB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the spike-field coherence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "[cohr, f, SYY, SNN, SYN] = coherence(A,y,t); plt.plot(f,cohr)\n",
    "\n",
    "[cohr, f, SYY, SNN, SYN] = coherence(B,y,t); plt.plot(f,cohr)\n",
    "\n",
    "plt.xlim([0,20])\n",
    "plt.ylim([0,1])\n",
    "plt.legend(['Neuron A', 'Neuron B'])\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('Coherence');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the LFP phase at each spike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi               = get_field_phase(y)\n",
    "phase_at_spikes_A = phi[A == 1]\n",
    "phase_at_spikes_B = phi[B == 1]\n",
    "\n",
    "plt.clf()\n",
    "plt.hist([phase_at_spikes_A,phase_at_spikes_B],density=True,);\n",
    "plt.xlabel('Phase')\n",
    "plt.ylabel('Counts')\n",
    "plt.legend(['Neuron A', 'Neuron B']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat coherence calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_A = 1.0;  coupling_A = 1.0       # Fix the rates and coupling to field for each neuron.\n",
    "rate_B = 0.5;  coupling_B = 0.5\n",
    "cohr_A = np.zeros([501,100])\n",
    "cohr_B = np.zeros([501,100])\n",
    "for k in np.arange(100):              # For 100 realizations, simulate the neurons & compute coherence.\n",
    "    A,B,y = sim_two_neurons(rate_A, rate_B, coupling_A, coupling_B)\n",
    "    [cohr, f, SYY, SNN, SYN] = coherence(A,y,t); cohr_A[:,k] = cohr\n",
    "    [cohr, f, SYY, SNN, SYN] = coherence(B,y,t); cohr_B[:,k] = cohr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the coherence results.\n",
    "plt.clf()\n",
    "mn = np.mean(cohr_A,1); se = np.std( cohr_A,1)/np.sqrt(np.shape(cohr_A)[1])\n",
    "plt.plot(f,mn,'b',label=\"Neuron A\"); plt.plot(f,mn-2*se, 'b:'); plt.plot(f,mn+2*se, 'b:');\n",
    "mn = np.mean(cohr_B,1); se = np.std( cohr_B,1)/np.sqrt(np.shape(cohr_B)[1])\n",
    "plt.plot(f,mn,'r',label=\"Neuron B\"); plt.plot(f,mn-2*se, 'r:'); plt.plot(f,mn+2*se, 'r:');\n",
    "plt.xlim([0,20]); plt.ylim([0,1]);\n",
    "plt.legend()\n",
    "plt.xlabel('Frequency [Hz]')\n",
    "plt.ylabel('Coherence');\n",
    "plt.title('Neuron A Rate: Baseline=' + str(rate_A) + ', Coupling=' + str(coupling_A) + '\\n'\n",
    "          'Neuron B Rate: Baseline=' + str(rate_B) + ', Coupling=' + str(coupling_B));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
